{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text data requires special preparation before you can start using it for predictive modeling. The\n",
    "text must be parsed to remove words, called tokenization. Then the words need to be encoded\n",
    "as integers or floating point values for use as input to a machine learning algorithm, called\n",
    "feature extraction (or vectorization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my': 5, 'name': 6, 'is': 4, 'saif': 7, 'gazali': 3, 'and': 2, 'age': 1, '22': 0}\n",
      "(1, 8)\n",
      "[[1 1 1 1 2 2 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Word Counts with CountVectorizer\n",
    "\n",
    "#The CountVectorizer provides a simple way to both tokenize a collection of text documents and build a vocabulary of known words, but also to encode new documents using that vocabulary\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer as cv\n",
    "\n",
    "vectorizer = cv()\n",
    "\n",
    "text = [\"My name is Saif Gazali and my age is 22\"]\n",
    "\n",
    "vectorizer.fit(text)\n",
    "\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "vectors = vectorizer.transform(text)\n",
    "\n",
    "print(vectors.shape)\n",
    "print(vectors.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# using the same vector on other text\n",
    "text2 = [\"his name is what ?\"]\n",
    "vector = vectorizer.transform(text2)\n",
    "print(vector.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
      "[1.69314718 1.28768207 1.28768207 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.        ]\n",
      "[[0.36388646 0.27674503 0.27674503 0.36388646 0.36388646 0.36388646\n",
      "  0.36388646 0.42983441]]\n"
     ]
    }
   ],
   "source": [
    "# Word Frequencies with tfidVectorizer\n",
    "\n",
    "#TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfv\n",
    "\n",
    "vectorizer = tfv()\n",
    "\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
    "\"The dog.\",\n",
    "\"The fox\"]\n",
    "\n",
    "\n",
    "vectorizer.fit(text)\n",
    "\n",
    "print(vectorizer.vocabulary_)\n",
    "\n",
    "print(vectorizer.idf_)\n",
    "#The inverse document frequencies are calculated for each word in the vocabulary, assigning the lowest score of 1.0 to the most frequently observed word: the at index 7.\n",
    "\n",
    "vector = vectorizer.transform([text[0]])\n",
    "\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing with HashingVectorizer\n",
    "Counts and frequencies can be very useful, but one limitation of these methods is that the\n",
    "vocabulary can become very large. This, in turn, will require large vectors for encoding\n",
    "documents and impose large requirements on memory and slow down algorithms. A clever work\n",
    "around is to use a one way hash of words to convert them to integers. The clever part is that\n",
    "no vocabulary is required and you can choose an arbitrary-long fixed length vector. A downside\n",
    "is that the hash is a one-way function so there is no way to convert the encoding back to a word\n",
    "(which may not matter for many supervised learning tasks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 20)\n",
      "[[ 0.          0.          0.          0.          0.          0.33333333\n",
      "   0.         -0.33333333  0.33333333  0.          0.          0.33333333\n",
      "   0.          0.          0.         -0.33333333  0.          0.\n",
      "  -0.66666667  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.70710678  0.          0.          0.          0.\n",
      "  -0.70710678  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.         -0.70710678  0.          0.\n",
      "  -0.70710678  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "#An arbitrary fixed-length vector size of 20 was chosen. This corresponds to the range of the hash function, where small values (like 20) may result in hash collisions.\n",
    "vectorizer = HashingVectorizer(n_features=20)\n",
    "\n",
    "vector = vectorizer.transform(text)\n",
    "\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
